# ğŸ¥ GLASS Data Standardizer

**Advanced Data Processing & Standardization Platform**

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue)](https://python.org)
[![Dash](https://img.shields.io/badge/Dash-2.17%2B-blue)](https://dash.plotly.com)
[![License](https://img.shields.io/badge/License-MIT-green)](LICENSE)

## ğŸš€ Quick Start

### Option 1: Automatic Setup (Recommended)
```bash
# Windows
start.bat

# Linux/macOS
python setup.py && python run.py
```

### Option 2: Manual Setup
```bash
# 1. Create virtual environment
python -m venv .venv

# 2. Activate virtual environment
# Windows:
.venv\Scripts\activate
# Linux/macOS:
source .venv/bin/activate

# 3. Install dependencies
pip install -r requirements.txt

# 4. Run application
python run.py
```

### Option 3: Docker (Recommended for Production)
```bash
docker compose up -d
# Access at http://localhost:8501
```

## ğŸ“‹ System Requirements

- **Python**: 3.8 or higher
- **Memory**: 4GB RAM minimum, 8GB recommended
- **Storage**: 1GB free space
- **OS**: Windows 10+, macOS 10.14+, Linux (Ubuntu 18.04+)

## âœ¨ Features

### Core Functionality
- **ğŸ“ Single File Processing**: Upload, analyze, transform, and export individual files
- **ğŸ“Š Multiple File Merging**: Intelligent merging of multiple Excel/CSV files
- **ğŸ§¬ AMR Analytics**: Professional antimicrobial resistance analysis with CLSI compliance
- **ğŸ”— Smart Column Mapping**: AI-powered column matching and mapping
- **ğŸ”„ Data Transformation**: Comprehensive data cleaning and standardization
- **ğŸ“ˆ Quality Assessment**: Advanced data quality metrics and validation
- **ğŸ“¤ Multi-format Export**: Export to CSV, Excel, JSON, XML formats

### AMR Analytics Features
- **ğŸ§¬ Professional Visualizations**: Publication-quality charts and heatmaps
- **ğŸ“Š CLSI Compliance**: Current antimicrobial resistance standards (M100-S33, M02-A13)
- **ğŸ›¡ï¸ Resistance Analysis**: MDR/XDR/PDR classification and resistance rates
- **ğŸ“ˆ Antibiogram Generation**: Interactive resistance heatmaps
- **ğŸ” Data Quality Assessment**: Comprehensive data validation and scoring
- **ğŸ“¥ Export Capabilities**: Professional reports and high-resolution charts

### Production Features
- **ğŸ›¡ï¸ Error Handling**: Comprehensive error logging and recovery
- **ğŸ“Š Performance Monitoring**: Real-time performance metrics and optimization
- **âœ… Data Validation**: Multi-level data validation and quality checks
- **ğŸ’¾ Memory Optimization**: Automatic DataFrame optimization
- **âš™ï¸ Configuration Management**: Centralized settings and customization

## ğŸ—ï¸ Architecture

```
data-standardizer/
â”œâ”€â”€ dash_app.py           # Main Dash application
â”œâ”€â”€ api/                  # FastAPI REST API
â”‚   â””â”€â”€ app.py           # API endpoints
â”œâ”€â”€ core/                 # Core services
â”‚   â”œâ”€â”€ services/        # Business logic services
â”‚   â”œâ”€â”€ schemas.py       # Pydantic data models
â”‚   â”œâ”€â”€ tasks.py         # Background job tasks
â”‚   â””â”€â”€ jobs.py          # Job queue management
â”œâ”€â”€ jobs/                 # Background workers
â”‚   â””â”€â”€ worker.py        # RQ worker
â”œâ”€â”€ utils/                # Core utility modules
â”‚   â”œâ”€â”€ ast_detector.py  # AST data type detection
â”‚   â”œâ”€â”€ glass_exporter.py # WHO GLASS export
â”‚   â”œâ”€â”€ whonet_exporter.py # WHONET export
â”‚   â”œâ”€â”€ glass_validator.py # GLASS validation
â”‚   â”œâ”€â”€ breakpoint_interpreter.py # S/I/R interpretation
â”‚   â”œâ”€â”€ vocabularies.py  # Controlled vocabularies
â”‚   â”œâ”€â”€ schema_analyzer.py # Schema analysis
â”‚   â””â”€â”€ validator.py     # Data validation
â”œâ”€â”€ tests/               # Unit and integration tests
â”œâ”€â”€ requirements.txt     # Python dependencies
â”œâ”€â”€ docker-compose.yml   # Docker Compose configuration
â”œâ”€â”€ Dockerfile          # Docker image definition
â””â”€â”€ README.md          # This file
```

## ğŸ”§ Usage

### Single File Workflow
1. **Upload**: Select and upload your data file (CSV, Excel)
2. **Analyze**: Review data structure and quality metrics
3. **Map**: Configure column mappings to target schema
4. **Transform**: Apply data cleaning and standardization
5. **Validate**: Verify data quality and completeness
6. **Export**: Download processed data in your preferred format

### Multiple File Workflow
1. **Upload**: Select multiple files for merging
2. **Validate**: Review file structures and compatibility
3. **Map**: Configure column mappings between files
4. **Merge**: Combine files with intelligent data handling
5. **Review**: Analyze merge statistics and data quality
6. **Export**: Download merged dataset

## ğŸ› ï¸ Configuration

The application uses a centralized configuration system:

- **App Settings**: File size limits, memory usage, processing options
- **UI Settings**: Theme, layout, display preferences
- **Data Processing**: Chunk sizes, optimization settings
- **Merging**: Similarity thresholds, mapping preferences
- **Export**: Default formats, compression options

## ğŸ“Š Data Quality Metrics

- **Completeness**: Percentage of non-null values
- **Consistency**: Data format and value consistency
- **Accuracy**: Data accuracy validation
- **Validity**: Data validity checks
- **Uniqueness**: Duplicate detection and analysis

## ğŸ” Troubleshooting

### Common Issues

1. **Python Not Found**
   - Install Python 3.8+ from https://python.org
   - Ensure Python is in PATH

2. **Dependencies Not Installing**
   - Check internet connection
   - Try: `pip install --upgrade pip`
   - Run setup.py again

3. **Port Already in Use**
   - Kill existing processes: `taskkill /f /im python.exe`
   - Or change port in `docker-compose.yml` or `dash_app.py`

4. **Virtual Environment Issues**
   - Delete .venv folder and run setup.py again
   - Ensure you have write permissions

### Getting Help

- Check the error messages in the terminal
- Review the application logs
- Ensure all system requirements are met
- Try running as administrator if on Windows

## ğŸ“ˆ Performance

- **Memory Optimization**: Automatic DataFrame optimization
- **Chunked Processing**: Large file handling
- **Caching**: Intelligent data caching
- **Monitoring**: Real-time performance metrics

## ğŸ”’ Security

- **Input Validation**: All inputs are validated
- **File Upload Limits**: Configurable file size restrictions
- **Error Information**: Controlled error disclosure
- **Memory Management**: Automatic cleanup

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request

## ğŸ“ Support

For technical support or issues:
1. Check the troubleshooting section
2. Review the application logs
3. Ensure system requirements are met
4. Check the deployment guide

---

**Version**: 2.0.0  
**Last Updated**: 2024  
**Compatibility**: Python 3.8+, Windows 10+, macOS 10.14+, Linux Ubuntu 18.04+

**Made with â¤ï¸ for data standardization and processing**